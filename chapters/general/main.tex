\section{Скользящий контроль}

Скользящий контроль (или кросс-проверка, кросс-валидация, англ. cross-validation, CV) — это метод эмпирической оценки  обобщающей способности алгоритмов, когда они обучаются на примерах из данных.

Метод основан на использовании некоторого числа разбиений исходной выборки на два подмножества: обучающей и контрольной подвыборок. Для каждого разбения выполняется обучение алгоритма на обучающей подвыборке, а затем рассчитывается средняя ошибка на контрольной подвыборке. Итоговой оценкой скользящего контроля является среднее значение ошибки по всем контрольным подвыборкам.

При условии независимости выборки средняя ошибка кросс-валидации даёт несмещённую оценку вероятности ошибки. Это преимущество выделяет её по сравнению со средней ошибкой на обучающей выборке, которая может быть смещена (занижена) из-за эффекта переобучения.

Скользящий контроль является стандартным методом для тестирования и сравнения алгоритмов классификации, регрессии и прогнозирования.

\section{Определения и обозначения}

Рассмотрим задачу обучения с учителем.

Пусть $X$ — множество, содержащее описания объектов, а $Y$ — множество возможных ответов.

Предположим, что имеется конечная выборка прецедентов $X^L = \{(x_i, y_i)\}_{i=1}^L \subset X \times Y$.

Задан алгоритм обучения — отображение $\mu$, которое сопоставляет произвольной конечной выборке прецедентов $X^m$ некоторую функцию (алгоритм) $a : X \to Y$.

Качество алгоритма $a$ оценивается по произвольной выборке прецедентов $X^m$ с использованием функционала качества $Q(a, X^m)$. Для процедуры скользящего контроля способ вычисления данного функционала может варьироваться, однако обычно он аддитивен по элементам выборки:

\[
Q(a, X^m) = \frac{1}{m} \sum_{x_i \in X^m} \mathcal{L}(a(x_i), y_i),
\]

где $\mathcal{L}(a(x_i), y_i)$ — неотрицательная функция потерь, показывающая величину ошибки алгоритма $a(x_i)$ при истинном ответе $y_i$.

\subsection{Процедура скользящего контроля}

Рассмотрим выборку $X^L$, которая разбивается на $N$ различных способов на две непересекающиеся подвыборки: $X^L = X^m_n \cup X^k_n$, где $X^m_n$ — обучающая подвыборка размера $m$, а $X^k_n$ — контрольная подвыборка длины $k = L - m$, при этом $n = 1, \ldots, N$ обозначает номер разбиения.

Для каждого разбиения $n$ рассчитывается алгоритм $a_n = \mu(X^m_n)$ и вычисляется значение функционала качества $Q_n = Q(a_n, X^k_n)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называют оценкой по методу скользящего контроля:

\[
CV(\mu, X^L) = \frac{1}{N} \sum_{n=1}^N Q(\mu(X^m_n), X^k_n).
\]

Разные методы скользящего контроля отличаются как видами функционала качества, так и способами разбиения выборки.

\subsection{Доверительное оценивание}

Кроме среднего значения качества на контроле, строятся также доверительные интервалы.

\textbf{Непараметрическая оценка доверительного интервала.}
\newline
Cтроится вариационный ряд значений $Q_n = Q(a_n, X^k_n)$, где $n = 1, \ldots, N$:

\[
Q^{(1)} \leq Q^{(2)} \leq \cdots \leq Q^{(N)}.
\]

\textbf{Утверждение 1.} Если разбиения осуществлялись случайно, независимо и равновероятно, то с вероятностью $\eta = \frac{t}{N+1}$ значение случайной величины $Q(a(X^m), X^k)$ не превосходит $Q^{(N-t+1)}$.

\textbf{Следствие 1.} Значение случайной величины $Q(a(X^m), X^k)$ не превосходит $Q^{(N)}$ с вероятностью $\eta = \frac{1}{N+1}$.

В частности, для получения верхней оценки с надёжностью 95\% достаточно взять $N=20$ разбиений.

\textbf{Утверждение 2.} Если разбиения осуществлялись случайно, независимо и равновероятно, то с вероятностью $\eta = \frac{2t}{N+1}$ значение случайной величины $Q(a(X^m), X^k)$ не выходит за границы доверительного интервала $\left[ Q^{(t)}, Q^{(N-t+1)} \right]$.

\textbf{Следствие 2.} Значение случайной величины $Q(a(X^m), X^k)$ не выходит за границы вариационного ряда $\left[ Q^{(1)}, Q^{(N)} \right]$ с вероятностью $\eta = \frac{2}{N+1}$.

В частности, для получения двусторонней оценки с надёжностью 95\% достаточно взять $N=40$ разбиений.

\textbf{Параметрические оценки доверительного интервала} основываются на априорном предположении о виде распределения случайной величины $Q(a(X^m), X^k)$. Если априорные предположения не выполняются, доверительный интервал может оказаться сильно смещённым. В частности, если предположения о нормальности распределения не выполнены, то нельзя использовать стандартное «правило двух сигм» или «трёх сигм». Джон Лангфорд в своей диссертации \cite{Langford2002} указывает на распространённую ошибку, когда правило двух сигм применяется к функционалу частоты ошибок, имеющему на самом деле биномиальное распределение. Однако биномиальным распределением в общем случае тоже нельзя пользоваться, поскольку в результате обучения по случайным подвыборкам $X^m$ вероятность ошибки алгоритма $a(X^m)$ оказывается случайной величиной. Следовательно, случайная величина $Q(a(X^m), X^k)$ описывается не биномиальным распределением, а (неизвестной) смесью биномиальных распределений. Аппроксимация смеси биномиальным распределением может приводить к ошибочному сужению доверительного интервала. Приведённые выше непараметрические оценки лишены этого недостатка.

\subsection{Стратификация}

Стратификация выборки представляет собой метод, направленный на уменьшение разброса (дисперсии) оценок, получаемых при скользящем контроле, что позволяет получить более узкие доверительные интервалы и более точные верхние оценки.

Процесс стратификации заключается в том, чтобы заранее разделить выборку на несколько частей (страты), и при разбиении на обучающую выборку длины $m$ и контрольную выборку длины $k$ обеспечить, чтобы каждая страта была представлена в обучении и контроле в одинаковых пропорциях $m:k$.

\textbf{Стратификация классов} в задачах классификации означает, что каждый класс делится между обучением и контролем в пропорции $m:k$.

\textbf{Стратификация по вещественному признаку} осуществляется следующим образом: объекты выборки сортируются по какому-либо критерию, например, по возрастанию значения одного из признаков. Затем выборка разбивается на $k$ последовательных страт одинаковой длины (с точностью до 1). При формировании контрольных выборок из каждой страты выбирается по одному объекту — либо с заданным порядковым номером внутри страты, либо случайным образом.


\section{Разновидности скользящего контроля}
Существует несколько различных методов скользящего контроля, которые могут отличаться по способу разбиения выборки.
\subsection{Полный скользящий контроль (complete CV)}
Оценка скользящего контроля строится по всем возможным $N = C_L^k$ разбиениям. В зависимости от длины обучающей выборки $k$ различают следующие варианты:
\begin{itemize}

\item \textbf{Частный случай при $k=1$ — контроль по отдельным объектам (leave-one-out CV)}

Как было показано, контроль по отдельным объектам является асимптотически оптимальным при определённых условиях, а именно:

\[
\frac{L_n(\hat{m})}{\inf_{m \in M_n} L_n(m)} \to 1 \quad \text{по вероятности},
\]

где:

\begin{itemize}
  \item $M_n$ — класс сравниваемых моделей;
  \item $L_n(m)$ — среднеквадратичная ошибка при выборе $m$-ой модели;
  \item $\hat{m} = \arg \min_{m \in M_n} \text{CV}(m)$.
\end{itemize}

\item \textbf{Общий случай при $k>2$}
\end{itemize}

В этом случае число разбиений $N = C_L^k$ становится очень большим, даже для сравнительно малых значений $k$, что делает практическое применение данного метода затруднительным. Для такого случая полный скользящий контроль используется либо в теоретических исследованиях \cite{Voronov2004}, либо в редких ситуациях, когда удаётся вывести эффективную вычислительную формулу. Например, для метода \textit{$k$ ближайших соседей} существует такая формула, которая позволяет эффективно выбирать параметр $k$.

\medskip
На практике чаще применяются другие варианты скользящего контроля.

\subsection{Случайные разбиения}

Разбиения $n = 1, \ldots, N$ выбираются случайным образом, независимо и с одинаковой вероятностью из множества всех возможных $C_L^k$ разбиений. Именно для такого случая верны приведённые выше оценки доверительных интервалов. На практике эти оценки обычно применяются без изменений и к другим методам разбиения выборки.

\subsection{Контроль на отложенных данных (hold-out CV)}
Оценка модели с использованием метода скользящего контроля основана на одном случайном разбиении выборки, где $N=1$.

Однако этот метод имеет несколько значительных недостатков:

\begin{enumerate}
    \item Часто приходится оставлять слишком много объектов в контрольной подвыборке, что приводит к сокращению обучающей выборки. Это уменьшение объема обучающей выборки вызывает смещение оценки (пессимистически завышенную вероятность ошибки).
    \item Оценка модели значительно зависит от конкретного разбиения данных, в то время как более предпочтительно, чтобы она характеризовала исключительно алгоритм обучения, а не случайность разбиения.
    \item Дисперсия оценки может быть высокой. Она может быть снижена путём усреднения оценок по нескольким разбиениям.
\end{enumerate}

Важно различать два типа контроля по отложенным данным и по тестовой выборке:

\begin{itemize}
    \item \textbf{Контроль по отложенным данным (Hold-out)} — оценка вероятности ошибки производится для классификатора, построенного по всей выборке.
    \item \textbf{Контроль по тестовой выборке (Test-set)} — оценка вероятности ошибки вычисляется для классификатора, обученного на обучающей подвыборке.
\end{itemize}

\subsection{Контроль по отдельным объектам (leave-one-out CV)}

Метод leave-one-out (LOO) является частным случаем полной кросс-валидации с использованием скользящего контроля при \( k = 1 \), что означает \( N = L \), где \( L \) — количество объектов в выборке. Это один из наиболее популярных вариантов скользящей кросс-валидации.

Основное преимущество LOO заключается в том, что каждый объект участвует в процессе контроля ровно один раз, при этом размер обучающих подвыборок лишь на единицу меньше общей выборки.

Однако метод LOO имеет и ряд недостатков, основным из которых является высокая вычислительная нагрузка, поскольку для каждого объекта выборки требуется провести обучение модели заново. В некоторых случаях, когда используемые алгоритмы обучения позволяют быстро адаптировать внутренние параметры при замене одного объекта на другой, процесс LOO можно значительно ускорить.

\subsection{Контроль по \( q \) блокам (q-fold CV)}

В методе \( q \)-fold кросс-валидации выборка случайным образом делится на \( q \) непересекающихся блоков, каждый из которых имеет одинаковую (или почти одинаковую) длину \( k_1, \ldots, k_q \):

\[
X^L = X^{k_1}_1 \cup \cdots \cup X^{k_q}_q, \quad k_1 + \dots + k_q = L.
\]

Каждый блок поочередно используется в качестве контрольной подвыборки, а обучение модели проводится на оставшихся \( q-1 \) блоках. Критерий ошибки определяется как среднее значение ошибки на контрольной подвыборке:

\[
CV(\mu, X^L) = \frac{1}{q} \sum_{n=1}^q Q \left( \mu \left( X^L \setminus X^{k_n}_n \right), X^{k_n}_n \right),
\]

где \( Q \) — функция потерь. Этот метод представляет собой компромисс между подходами LOO, hold-out и случайными разбиениями. С одной стороны, обучение проводится только \( q \) раз, а не \( L \). С другой стороны, длина обучающих подвыборок, равная \( L \frac{q-1}{q} \) с точностью до округления, практически не отличается от длины всей выборки \( L \). Обычно выборку делят случайным образом на 10 или 20 блоков.

\subsection{Контроль по r×q блокам (r×q-fold CV)}
Контроль с использованием \(r \times q\)-кратного разбиения (или \(r \times q\)-fold кросс-валидации) представляет собой метод, при котором процедура \(q\)-кратной кросс-валидации повторяется \(r\) раз. В каждом повторении данные случайным образом делятся на \(q\) непересекающихся блоков, обеспечивая полное покрытие выборки. Этот метод сохраняет все преимущества стандартной \(q\)-кратной кросс-валидации, добавляя при этом гибкость в выборе количества разбиений.

Данный подход стратифицированного скользящего контроля считается одной из базовых методик для оценки и сравнения производительности алгоритмов классификации. Он широко используется в таких системах, как WEKA и «Полигон алгоритмов».

Метод скользящего контроля применяется также в задачах прогнозирования.


\section{Скользящий контроль в задачах прогнозирования}

В задачах прогнозирования, динамического обучения, обучения с подкреплением и активного обучения примеры часто линейно упорядочены по времени их появления. В таких случаях возможности применения различных вариантов скользящего контроля ограничены.

\subsection{Контроль с нарастающей длиной обучения}  Предполагается, что обучающая подвыборка включает все предыдущие наблюдения: \( X^m_n = \{x_1, \ldots, x_n\} \). Контрольная подвыборка состоит из последующих наблюдений: \( X^k_n = \{x_{n+\delta+1}, \ldots, x_{n+\delta+k}\} \), где \(\delta \geq 0\) — величина задержки прогноза (как правило, \(\delta = 0\)). Момент «текущего времени» \(n\) перемещается по выборке:

\[
CV(\mu, X^L) = \frac{1}{T_2 - T_1 + 1} \sum_{n=T_1}^{T_2} Q \left(\mu(X^m_n), X^k_n\right),
\]

где \(T_1\) — минимальная длина обучающей выборки, необходимая для корректной работы алгоритма обучения \(\mu\), \(T_2 = L - \delta - k\).

Так как длина обучающей подвыборки \(m = n\) увеличивается со временем, точность прогнозов алгоритма может постепенно возрастать. Этот эффект может быть нежелательным, если цель скользящего контроля — объективная оценка качества алгоритма обучения.

\subsection{Контроль с фиксированной длиной обучения} Отличается от метода с нарастающей длиной тем, что размер обучающей подвыборки \(m\) остаётся постоянным, включающим только последние \(m\) примеров временного ряда: \( X^m_n = \{x_{n-m+1}, \ldots, x_n\} \). В этом случае минимальная длина обучающей выборки принимается равной \(T_1 = m\).


\section{Недостатки скользящего контроля}
\begin{itemize}
\item При использовании скользящего контроля обучение выполняется \( N \) раз, что связано с высокими вычислительными затратами. 
\item Оценка скользящего контроля предполагает наличие заранее заданного алгоритма обучения \( \mu \), но она не раскрывает, какими свойствами должны обладать "хорошие" алгоритмы обучения и как их можно построить. В этом смысле теоретические оценки обобщающей способности могут давать полезные рекомендации.

\item Попытка применить скользящий контроль как критерий оптимизации в процессе обучения приводит к утрате его несмещённости, что увеличивает риск переобучения. 
\item Скользящий контроль предоставляет несмещённую точечную оценку риска, но не интервальную. На данный момент нет методов, которые позволяли бы на основе скользящего контроля строить точные доверительные интервалы для риска, то есть для математического ожидания потерь (включая вероятность ошибочной классификации).
\end{itemize}

\section{Применение скользящего контроля}

Скользящий контроль широко используется на практике для настройки некоторых ключевых параметров, которые, как правило, определяют структуру или сложность модели алгоритма и имеют ограниченное количество возможных значений.

Примеры применения:

\begin{itemize}
    \item Выбор модели из ограниченного набора альтернативных алгоритмов.
    \item Оптимизация параметра регуляризации, включая:
    \begin{itemize}
        \item параметр регуляризации в гребневой регрессии;
        \item параметр весового затухания (weight decay) в нейронных сетях;
        \item параметр \( C \) в методе опорных векторов.
    \end{itemize}
    \item Настройка ширины окна в методах:
    \begin{itemize}
        \item парзеновского окна;
        \item ближайшего соседа;
        \item ядерного сглаживания.
    \end{itemize}
    \item Оптимизация количества нейронов в скрытом слое многослойной нейронной сети.
    \item Выбор информативного набора признаков.
    \item Сокращение решающего дерева.
    \item Минимизация структурного риска.
\end{itemize}

\begin{thebibliography}{5}

\bibitem{Voronov2004}
Воронцов К. В. Комбинаторный подход к оценке качества обучаемых алгоритмов. — Математические вопросы кибернетики. М.: Физматлит, 2004.

\bibitem{Efron1988}
Эфрон Б. Нетрадиционные методы многомерного статистического анализа. — М: Финансы и статистика. — 1988.

\bibitem{Langford2002}
Langford J. Quantitatively Tight Sample Complexity Bounds. — Carnegie Mellon Thesis. — 2002. — 124 с.
\bibitem{Kohavi2002}
Kohavi R. A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection. — 14th International Joint Conference on Artificial Intelligence, Palais de Congres Montreal, Quebec, Canada. — 1995. — С. 1137-1145.
\bibitem{Mullin2000}
Mullin M., Sukthankar R. Complete Cross-Validation for Nearest Neighbor Classifiers. — Proceedings of International Conference on Machine Learning. — 2000. — С. 1137-1145.

\end{thebibliography}

\section*{Задача: Cross-Validation (LOOCV)}

У вас есть набор данных, состоящий из 6 объектов:
\[
D = \{ (x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4), (x_5, y_5), (x_6, y_6) \},
\]
где \( y \) — целевая переменная, которая может принимать значение \( 0 \) или \( 1 \).

Простая линейная модель для предсказания \( y \) задана как:
\[
y = a \cdot x + b,
\]
где параметры \( a \) и \( b \) нужно подобрать с помощью обучения на обучающей выборке.

\subsection*{Требуется:}
\begin{enumerate}
    \item Используйте \textbf{leave-one-out cross-validation (LOOCV)} для оценки качества модели.
    \item Для каждой итерации используйте метод наименьших квадратов для подбора параметров \( a \) и \( b \) по формулам:
    \[
    a = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}, \quad b = \bar{y} - a \cdot \bar{x}.
    \]
    \item Проведите LOOCV:
    \begin{itemize}
        \item На каждой итерации оставьте одно наблюдение для тестирования и обучайте модель на оставшихся данных.
        \item Рассчитайте параметры \( a \) и \( b \) для каждой подвыборки.
        \item Используя найденные параметры, предскажите \( y \) для отложенного объекта.
    \end{itemize}
    \item Рассчитайте среднеквадратическую ошибку (MSE) на тестовых объектах:
    \[
    \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2.
    \]
\end{enumerate}

\subsection*{Данные:}
Таблица с наблюдениями:

\[
\begin{array}{|c|c|c|}
\hline
\text{Объект } i & x_i & y_i \\
\hline
1 & 1 & 0 \\
2 & 2 & 0 \\
3 & 3 & 1 \\
4 & 4 & 1 \\
5 & 5 & 1 \\
6 & 6 & 0 \\
\hline
\end{array}
\]

\section*{Решение задачи LOOCV}


\subsection*{1. Процедура LOOCV:}
\begin{itemize}
    \item На каждой итерации исключаем одно наблюдение из выборки для тестирования.
    \item Обучаем модель на оставшихся наблюдениях.
    \item Рассчитываем параметры линейной модели по формулам:
    \[
    a = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}, \quad b = \bar{y} - a \cdot \bar{x},
    \]
    где \(\bar{x}\) и \(\bar{y}\) — средние значения \(x\) и \(y\) на обучающей выборке.
    \item Предсказываем \(y\) для тестового объекта:
    \[
    \hat{y} = a \cdot x + b.
    \]
\end{itemize}

\subsection*{2. Итерации:}
Рассмотрим все 6 итераций:
\begin{itemize}
    \item \textbf{Итерация 1:} Тестовый объект \( (x_1 = 1, y_1 = 0) \)
    \begin{itemize}
        \item Обучающая выборка: \( (x, y) = \{(2, 0), (3, 1), (4, 1), (5, 1), (6, 0)\} \).
        \item Найденные параметры: \( a_1, b_1 \).
        \item Предсказание: \( \hat{y}_1 \).
        \item Ошибка: \( (y_1 - \hat{y}_1)^2 \).
    \end{itemize}
    \item \textbf{Итерация 2:} Тестовый объект \( (x_2 = 2, y_2 = 0) \)
    \begin{itemize}
        \item Обучающая выборка: \( (x, y) = \{(1, 0), (3, 1), (4, 1), (5, 1), (6, 0)\} \).
        \item Найденные параметры: \( a_2, b_2 \).
        \item Предсказание: \( \hat{y}_2 \).
        \item Ошибка: \( (y_2 - \hat{y}_2)^2 \).
    \end{itemize}
    \item Аналогично повторяем для всех объектов \( i = 3, 4, 5, 6 \).
\end{itemize}

\subsection*{3. Среднеквадратическая ошибка:}
Рассчитываем MSE:
\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,
\]
где \( n = 6 \).

\subsection*{4. Результат:}
\[
\text{MSE} \approx 0.653
\]

\section*{Задача: Кросс-валидация для классификации (5-Fold)}

Вам дан набор данных из 10 объектов:
\[
D = \{ (x_1, y_1), (x_2, y_2), \dots, (x_{10}, y_{10}) \},
\]
где \( x_i \) — признак (вещественное число), а \( y_i \) — метка класса (\( 0 \) или \( 1 \)).

Модель классификации представляет собой простое пороговое правило:
\[
\hat{y} =
\begin{cases} 
1, & \text{если } x \geq t, \\
0, & \text{если } x < t,
\end{cases}
\]
где \( t \) — порог, который нужно определить.

\subsection*{Требуется:}
\begin{enumerate}
    \item Разбейте данные на 5 фолдов для \textbf{5-Fold Cross-Validation}.
    \item Для каждого фолда:
    \begin{itemize}
        \item Используйте 4 фолда для обучения (подберите оптимальный порог \( t \)) и 1 фолд для тестирования.
        \item Подберите \( t \), чтобы минимизировать число ошибок классификации (ошибок предсказания).
    \end{itemize}
    \item Рассчитайте среднюю точность (accuracy) на тестовых фолдах:
    \[
    \text{Accuracy} = \frac{\text{Число верных предсказаний}}{\text{Общее число объектов}}.
    \]
\end{enumerate}

\subsection*{Данные:}
Таблица с наблюдениями:

\[
\begin{array}{|c|c|c|}
\hline
\text{Объект } i & x_i & y_i \\
\hline
1 & 1.2 & 0 \\
2 & 2.3 & 0 \\
3 & 2.8 & 0 \\
4 & 3.4 & 1 \\
5 & 4.1 & 1 \\
6 & 4.8 & 1 \\
7 & 5.5 & 1 \\
8 & 6.0 & 1 \\
9 & 6.7 & 0 \\
10 & 7.5 & 0 \\
\hline
\end{array}
\]

\subsection*{Упрощение для решения:}
\begin{itemize}
    \item Разделите данные по порядку: первые 2 объекта в первый фолд, следующие 2 — во второй, и так далее.
    \item Для каждого обучающего фолда подберите порог \( t \), перебрав средние значения между соседними объектами \( x_i \).
    \item Для упрощения расчетов: оптимизация \( t \) и проверка классификации выполняются с помощью простых сравнений.
\end{itemize}

\section*{Решение задачи: Кросс-валидация для классификации (5-Fold)}

\subsection*{Шаг 1: Разбиение данных на 5 фолдов}

Каждый фолд состоит из двух объектов. Разбиение:
\[
\begin{aligned}
\text{Фолд 1:} & \quad \{(1.2, 0), (2.3, 0)\}, \\
\text{Фолд 2:} & \quad \{(2.8, 0), (3.4, 1)\}, \\
\text{Фолд 3:} & \quad \{(4.1, 1), (4.8, 1)\}, \\
\text{Фолд 4:} & \quad \{(5.5, 1), (6.0, 1)\}, \\
\text{Фолд 5:} & \quad \{(6.7, 0), (7.5, 0)\}.
\end{aligned}
\]

\subsection*{Шаг 2: Выбор оптимального порога \( t \) для каждого фолда}

Для обучения используется объединение 4 фолдов, а пятый фолд служит тестовым. 

\subsubsection*{Фолд 1: Тестовый фолд \(\{(1.2, 0), (2.3, 0)\}\)}
Обучающая выборка:
\[
\{(2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Проверяем пороги \( t \) (средние значения между \( x_i \)):
\[
\begin{aligned}
t_1 = \frac{2.8 + 3.4}{2} = 3.1, & \quad t_2 = \frac{3.4 + 4.1}{2} = 3.75, \\
t_3 = \frac{4.1 + 4.8}{2} = 4.45, & \quad \dots, \quad t_7 = \frac{6.7 + 7.5}{2} = 7.1.
\end{aligned}
\]
Оптимальный порог \( t = 3.1 \) минимизирует ошибки. Тестируем: обе точки \((1.2, 0)\) и \((2.3, 0)\) классифицируются верно. 

\(\text{Accuracy}_1 = 1.0\).

\subsubsection*{Фолд 2: Тестовый фолд \(\{(2.8, 0), (3.4, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 3.75 \). Тестируем:
\[
\begin{aligned}
\hat{y}(2.8) = 0 \quad (\text{верно}), & \quad \hat{y}(3.4) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_2 = 1.0\).

\subsubsection*{Фолд 3: Тестовый фолд \(\{(4.1, 1), (4.8, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (5.5, 1), (6.0, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 4.5 \). Тестируем:
\[
\begin{aligned}
\hat{y}(4.1) = 1 \quad (\text{верно}), & \quad \hat{y}(4.8) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_3 = 1.0\).

\subsubsection*{Фолд 4: Тестовый фолд \(\{(5.5, 1), (6.0, 1)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (6.7, 0), (7.5, 0)\}.
\]
Оптимальный порог \( t = 5.75 \). Тестируем:
\[
\begin{aligned}
\hat{y}(5.5) = 1 \quad (\text{верно}), & \quad \hat{y}(6.0) = 1 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_4 = 1.0\).

\subsubsection*{Фолд 5: Тестовый фолд \(\{(6.7, 0), (7.5, 0)\}\)}
Обучающая выборка:
\[
\{(1.2, 0), (2.3, 0), (2.8, 0), (3.4, 1), (4.1, 1), (4.8, 1), (5.5, 1), (6.0, 1)\}.
\]
Оптимальный порог \( t = 6.35 \). Тестируем:
\[
\begin{aligned}
\hat{y}(6.7) = 0 \quad (\text{верно}), & \quad \hat{y}(7.5) = 0 \quad (\text{верно}).
\end{aligned}
\]
\(\text{Accuracy}_5 = 1.0\).

\subsection*{Шаг 3: Средняя точность}
Средняя точность:
\[
\text{Accuracy}_{\text{mean}} = \frac{\text{Accuracy}_1 + \text{Accuracy}_2 + \text{Accuracy}_3 + \text{Accuracy}_4 + \text{Accuracy}_5}{5} = 1.0.
\]

\subsection*{Вывод}
Модель с оптимальными порогами \( t \) классифицировала все объекты правильно на каждом из фолдов. Средняя точность составляет \( \mathbf{100\%} \).


\section*{Задача: Кросс-валидация для оценки среднего значения}

У вас есть набор данных, содержащий измеренные значения некоторой величины:
\[
D = \{ x_1, x_2, x_3, \dots, x_{12} \},
\]
где \(x_i\) — вещественное число. Вам необходимо оценить среднее значение этой величины и одновременно оценить, насколько точно модель предсказывает новые значения, используя технику кросс-валидации.

---

\subsection*{Требуется:}
1. Проведите разбиение данных на \textbf{4 фолда} для выполнения 4-Fold Cross-Validation.  
2. Для каждого фолда:
   \begin{itemize}
       \item Используйте 3 фолда для расчета среднего значения \(\bar{x}\).  
       \item Используйте 1 фолд для тестирования, чтобы рассчитать абсолютное отклонение предсказанного среднего \(\bar{x}\) от истинных значений.
   \end{itemize}
3. Рассчитайте среднее абсолютное отклонение (MAE) по всем тестовым фолдам:
\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert x_i - \bar{x} \rvert,
\]
где \(n\) — количество объектов в тестовых фолдах.

---

\subsection*{Данные:}
Таблица с измерениями:

\[
\begin{array}{|c|c|}
\hline
\text{Объект } i & x_i \\
\hline
1 & 5.1 \\
2 & 4.8 \\
3 & 6.2 \\
4 & 5.7 \\
5 & 5.4 \\
6 & 6.0 \\
7 & 5.3 \\
8 & 4.9 \\
9 & 6.1 \\
10 & 5.8 \\
11 & 5.5 \\
12 & 6.3 \\
\hline
\end{array}
\]

---

\subsection*{Упрощение для решения:}
\begin{itemize}
    \item Разделите данные на 4 фолда последовательно: первые 3 объекта в первый фолд, следующие 3 — во второй и так далее.  
    \item Расчеты среднего \(\bar{x}\) и абсолютных отклонений выполняйте вручную для каждого фолда.  
    \item Итоговая метрика MAE рассчитывается как среднее значение всех абсолютных отклонений.
\end{itemize}


\section*{Решение: Кросс-валидация для оценки среднего значения}

\subsection*{Шаг 1. Разбиение данных на фолды}
Разделим данные \(D = \{5.1, 4.8, 6.2, 5.7, 5.4, 6.0, 5.3, 4.9, 6.1, 5.8, 5.5, 6.3\}\) на 4 фолда:
\[
\text{Фолд 1: } \{5.1, 4.8, 6.2\}, \quad
\text{Фолд 2: } \{5.7, 5.4, 6.0\},
\]
\[
\text{Фолд 3: } \{5.3, 4.9, 6.1\}, \quad
\text{Фолд 4: } \{5.8, 5.5, 6.3\}.
\]

\subsection*{Шаг 2. Расчёт среднего значения и абсолютных отклонений для каждого фолда}
Для каждого фолда используем три других фолда для расчёта среднего значения \(\bar{x}\) и тестируем на оставшемся фолде.

\subsubsection*{Фолд 1 (тест): \{5.1, 4.8, 6.2\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_1 = \frac{5.7 + 5.4 + 6.0 + 5.3 + 4.9 + 6.1 + 5.8 + 5.5 + 6.3}{9} = 5.67.
\]
Абсолютные отклонения:
\[
|5.1 - 5.67| = 0.57, \quad |4.8 - 5.67| = 0.87, \quad |6.2 - 5.67| = 0.53.
\]

\subsubsection*{Фолд 2 (тест): \{5.7, 5.4, 6.0\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_2 = \frac{5.1 + 4.8 + 6.2 + 5.3 + 4.9 + 6.1 + 5.8 + 5.5 + 6.3}{9} = 5.55.
\]
Абсолютные отклонения:
\[
|5.7 - 5.55| = 0.15, \quad |5.4 - 5.55| = 0.15, \quad |6.0 - 5.55| = 0.45.
\]

\subsubsection*{Фолд 3 (тест): \{5.3, 4.9, 6.1\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_3 = \frac{5.1 + 4.8 + 6.2 + 5.7 + 5.4 + 6.0 + 5.8 + 5.5 + 6.3}{9} = 5.64.
\]
Абсолютные отклонения:
\[
|5.3 - 5.64| = 0.34, \quad |4.9 - 5.64| = 0.74, \quad |6.1 - 5.64| = 0.46.
\]

\subsubsection*{Фолд 4 (тест): \{5.8, 5.5, 6.3\}}
Среднее значение \(\bar{x}\), рассчитанное по остальным фолдам:
\[
\bar{x}_4 = \frac{5.1 + 4.8 + 6.2 + 5.7 + 5.4 + 6.0 + 5.3 + 4.9 + 6.1}{9} = 5.49.
\]
Абсолютные отклонения:
\[
|5.8 - 5.49| = 0.31, \quad |5.5 - 5.49| = 0.01, \quad |6.3 - 5.49| = 0.81.
\]

\subsection*{Шаг 3. Итоговая метрика MAE}
Среднее абсолютное отклонение рассчитывается как:
\[
\text{MAE} = \frac{\sum_{i=1}^{12} |x_i - \bar{x}|}{12}.
\]
Подставляем рассчитанные значения:
\[
\text{MAE} = \frac{0.57 + 0.87 + 0.53 + 0.15 + 0.15 + 0.45 + 0.34 + 0.74 + 0.46 + 0.31 + 0.01 + 0.81}{12} = 0.49.
\]

\subsection*{Ответ:}
Среднее абсолютное отклонение (MAE): \boxed{0.49}


\section{Вероятность переобучения}

Рассмотрим объединенную выборку обучение + контроль:
\begin{equation*}
    X^L=\{ x_1, \dots , x_L \} - \text{конечное} \textit{ генеральное множество } \text{объектов};
\end{equation*}
и
\begin{equation*}
    A=\{ a_1, \dots , a_D \} - \text{конечное} \textit{ семейство алгоритмов};
\end{equation*}

т. е. те алгоритмы, среди которых мы выбираем (делаем Model \newline Selection или делаем обучения по обучающей выборке). Пусть при этом функция потерь бинарна, т. е. у нас есть индикатор ошибки (условие того, что алгоритм $a$ ошибается на объекте $x$):
\begin{equation*}
    \mathcal{L} ( a, x ) \equiv I ( a, x ) = [ \text{алгоритм $a$ ошибается на объекте $x$ } ].
\end{equation*}

Тогда естесственным образом возникает матрица ошибок (не путать с матрицей объект-признак) $-$ у нее по строчкам объекты, а по столбцам $-$ наши алгоритмы (каждый столбец $-$ бинарный вектор, на каких объектах ошибся наш алгоритм):

\begin{table}[hbt!]
    \begin{tabular}{c|cccccccc|p{5cm}}
            & $a_1$ & $a_2$ & $a_3$ & $a_4$ & $a_5$ & $a_6$ & $\dots$ & $a_D$ & \\
    \hline
    $x_1$     & 1   & 1   & 0   & \textcolor{green}{\textbf{0}} & 0   & 1   & $\dots$ & 1   & \multirow{3}{*}{\parbox{5cm}{$X^l$ $-$ наблюдаемая (обучающая) выборка длины $l$}} \\
    \dots   & 0   & 0   & 0   & \textcolor{green}{\textbf{0}} & 1   & 1   & $\dots$ & 1   & \\
    $x_l$     & 0   & 0   & 1   & \textcolor{green}{\textbf{0}} & 0   & 0   & $\dots$ & 0   & \\
    \hline
    $x_{l+1}$ & 0   & 0   & 0   & \textcolor{red}{\textbf{1}}   & 1   & 1   & $\dots$ & 0   & \multirow{3}{*}{\parbox{5cm}{$X^k$ $-$ скрытая (контрольная) выборка длины $k=L-l$}} \\
    \dots   & 0   & 0   & 0   & \textcolor{red}{\textbf{1}}   & 0   & 0   & $\dots$ & 1   & \\
    $x_L$     & 0   & 1   & 1   & \textcolor{red}{\textbf{1}}   & 1   & 1   & $\dots$ & 0   & \\
    \end{tabular}
    \caption{$L \times D$ $-$ матрица ошибок с попарно различными столбцами}
\end{table}

На столбце $a_4$ мы как раз видим переобучение $-$ на обучающих объектах 0 ошибок, а на контрольных $-$ все ошибки (идеально плохая ситуация). Фишка в том, что мы начнем разбивать генеральную выборку всеми возможными способами на обучение и контроль (их всего $C_{l+k}^l$). Обозначим
\begin{equation*}
    n(a, X)= \sum_{x \in X} I(a, x) - \text{число ошибок } a \in A \text{ на выборке } X \subset X^L;
\end{equation*}
\begin{equation*}
    \nu(a, X)= n(a, X)/ | X | - \text{частота ошибок } a \text{ на выборке } X.
\end{equation*}

Нам придется сравнивать частоты ошибок на обучении и на контроле. Их разность $-$ это и есть переобученность. Посмотрим на примере, откуда вообще берется матрица ошибок:, 

\textbf{Пример 1.}

Пусть у нас есть выборка из 10 объектов, 5 объектов одного класса и 5 другого. Строим линейные классификаторы. В матрице ошибок есть один нулевой вектор (линейный классификатор без ошибок см. рис. \ref{fig:pic1}), 5 векторов с одной ошибкой (рис. \ref{fig:pic2} и т. д.). Вот откуда берется матрица ошибок. Максимально в ней может быть $2^l$ вектор-столбцов.

  \begin{figure}[hbt!]
    \begin{tikzpicture}
        \begin{axis}[
            axis lines = box,
            xmin=-4, xmax=12,
            ymin=-4, ymax=8,
        ]
    
        % Синие точки
        \addplot[only marks, mark=*, color=blue] coordinates {(5, 6) (6, 3) (10, 4) (9, 7) (11, 6)};
        \node[black] at (axis cs:5, 6) [above] {$x_4$};
        \node[black] at (axis cs:6, 3) [above right] {$x_5$};
        \node[black] at (axis cs:10, 4) [above right] {$x_6$};
        \node[black] at (axis cs:9, 7) [below left] {$x_9$};
        \node[black] at (axis cs:11, 6) [above] {$x_{10}$};
    
        % Красные точки
        \addplot[only marks, mark=*, color=red] coordinates {(-1, 2) (3, 2) (5, -3) (3, -2) (-3, -1)};
        \node[black] at (axis cs:-1, 2) [above left] {$x_1$};
        \node[black] at (axis cs:3, 2) [above left] {$x_2$};
        \node[black] at (axis cs:5, -3) [below right] {$x_3$};
        \node[black] at (axis cs:3, -2) [below left] {$x_7$};
        \node[black] at (axis cs:-3, -1) [below right] {$x_8$};
    
        % Фиолетовый отрезок
        \addplot[color=purple, thick] coordinates {(8, -3) (0, 7)};
        
        \end{axis}
    \end{tikzpicture}
    \caption{линейный классификатор без ошибок}
    \label{fig:pic1}
  \end{figure}

  \begin{figure}[hbt!]
    \begin{tikzpicture}
        \begin{axis}[
            axis lines = box,
            xmin=-4, xmax=12,
            ymin=-4, ymax=8,
        ]
    
        % Синие точки
        \addplot[only marks, mark=*, color=blue] coordinates {(5, 6) (6, 3) (10, 4) (9, 7) (11, 6)};
        \node[black] at (axis cs:5, 6) [above] {$x_4$};
        \node[black] at (axis cs:6, 3) [above right] {$x_5$};
        \node[black] at (axis cs:10, 4) [above right] {$x_6$};
        \node[black] at (axis cs:9, 7) [below left] {$x_9$};
        \node[black] at (axis cs:11, 6) [above] {$x_{10}$};
    
        % Красные точки
        \addplot[only marks, mark=*, color=red] coordinates {(-1, 3) (3, 2) (5, -3) (3, -2) (-3, -1)};
        \node[black] at (axis cs:-1, 3) [above left] {$x_1$};
        \node[black] at (axis cs:3, 2) [above left] {$x_2$};
        \node[black] at (axis cs:5, -3) [below right] {$x_3$};
        \node[black] at (axis cs:3, -2) [below left] {$x_7$};
        \node[black] at (axis cs:-3, -1) [below right] {$x_8$};
    
        % Фиолетовый отрезок
        \addplot[color=purple, thick] coordinates {(4, -3) (4, 6)};
        \addplot[color=purple, thick] coordinates {(4, 7) (10, -3)};
        \addplot[color=purple, thick] coordinates {(6, -3) (5.5, 7)};
        \addplot[color=purple, thick] coordinates {(-3, 2.5) (11, 2)};
        \addplot[color=purple, thick] coordinates {(8, -3) (-3, 6)};
        
        \end{axis}
    \end{tikzpicture}
    \caption{линейный классификатор с 1 ошибкой}
    \label{fig:pic2}
  \end{figure}

\begin{table}[hbt!]
    \begin{tabular}{c|c|ccccc|c}
		$x_1$ & 0 & 1 & 0 & 0 & 0 & 0 & \dots \\
    $x_2$ & 0 & 0 & 1 & 0 & 0 & 0 & \dots \\
		$x_3$ & 0 & 0 & 0 & 1 & 0 & 0 & \dots \\
    $x_4$ & 0 & 0 & 0 & 0 & 1 & 0 & \dots \\
    $x_5$ & 0 & 0 & 0 & 0 & 0 & 1 & \dots \\
    $x_6$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_7$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_8$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_9$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    $x_{10}$ & 0 & 0 & 0 & 0 & 0 & 0 & \dots \\
    \end{tabular}
    \caption{матрица ошибок для примера 1}
\end{table}

Наша задача будет оценивать вероятность переобучения. Для начала дадим несколько определений.
Вероятностное пространтво $-$ это равновероятное разбиение выборки на 2 части (train $X^l$ и test $X^k$). Интерпретация этому это гипотеза, что наша выборка IID (independent and identically distributed). Т. е. как бы мы эту выборку не упорядочивали, все ее упорядочивания равновероятны (как бы мы ее не разбивали на две части, все разбиения равновероятны). Это есть гипотеза простой выборки.

\textit{Замечание.} С другой стороны на это можно смотреть, как на Complete Cross Validation (полный скользящий контроль). Всеми способами разбиваем выборку на train и test. Потом по всем этим способам вероятность любого события, зависящая от этого разбиения, усредняем по всем разбиениям. В этой вероятностной интерпретации очень удобно, что математическое ожидание есть просто усреднение по всем разбиениям выборки
\begin{equation*}
    P \equiv E \equiv \frac{1}{C_L^l} \sum_{X^l \subset X^L}.
\end{equation*}

Переобученность $-$ это разность частот ошибок на $X^k$ и на $X^l$ (обучились на $X^l$, частоту ошибок посчитали на $X^k$, частота ошибок нормирована от 0 до 1):
\begin{equation*}
    \delta (\mu, X^l, X^k)=\nu (\mu(X^l), X^k ) - \nu(\mu(X^l), X^l ).
\end{equation*}

Переобучение $-$ это событие $\delta (\mu, X^l, X^k) \geq \varepsilon$ для фиксированного $\varepsilon$.

Основная наша задача $-$ оценить \textit{вероятность} переобучения (вероятность в смысле доли разбиения выборки, на которых $\delta$ оказалась $\geq \varepsilon$ при заданном $\varepsilon$):
\begin{equation*}
    R_{\varepsilon}(\mu, X^L) = P [\delta(\mu, X^l, X^k) \geq \varepsilon].
\end{equation*}

Теперь наша задача $-$ научиться сверху оценивать эту величину. Рассмотрим простейший, но важный частный случай.

Пусть у нас нет никакого выбора алгоритма, научимся оценивать вероятность переобучения хотя бы для одного отдельно взятого алгоритма, т. е. для одного вектор-столбца матрицы ошибок.
Пусть $A = {a}$ $-$ одноэлементарное множество, $m=n(a, X^L)$. Тогда вероятность переобучения есть вероятность большого отклонения частот ошибок в двух подвыборках:

\begin{equation*}
    R_{\varepsilon}(a, X^L) = P [\nu(a, X^k) - \nu(a, X^l) \geq \varepsilon].
\end{equation*}

\textbf{Теорема} Для любой выборки $X^l$, любого $\varepsilon \in [0, 1]$ вероятность большого отклонения частот ошибок в двух подвыборках для фиксированного вектора ошибок:
$$R_{\varepsilon}(a, X^L)=\mathcal{H}_L^{l, m}(\frac{l}{L}(m-\varepsilon k)),$$
где $\mathcal{H}_L^{l, m}(x)=\sum_{s=0}^{\lfloor x \rfloor}\frac{C_m^s C_{L-m}^{l-s}}{C_L^l}$ $-$ функция гипергеометрического распределения (ее левый хвост).

\textbf{Доказательство.}
$\square$ Обозначим число ошибок на обучении как $s=n(a, X^l)$. Аналогия со 2 задачей из упражнения,  где $m$ $-$ количество объектов с ошибками, $l$ $-$ обучающая выборка (гипергеометрическое распределение):
\begin{equation*}
    P[n(a, X^l)=s]=C_m^s C_{L-m}^{l-s}/C_L^l.
\end{equation*}
Распишем $R_{\varepsilon}$, подставив в него $\nu(a, X^k)=\frac{m-s}{k}$, $\nu(a, X^l)=\frac{s}{l}$ (частота ошибок на обучении $\frac{s}{l}$, а на контроле $\frac{m-s}{k}$) и учитывая тот факт, что $\frac{m-s}{k}-\frac{s}{l}$ есть переобученность:
\begin{multline*}
    R_{\varepsilon}(a, X^L)=P[\nu(a, X^k)-\nu(a, X^l) \geq \varepsilon] = \\
    = \sum_{s=0}^l [\underbrace{\frac{m-s}{k}-\frac{s}{l} \geq \varepsilon}_{s \leq \frac{l}{L}(m-\varepsilon k)}]\underbrace{P[n(a, X^l)=s]}_{C_m^s C_{L-m}^{l-s}/C_L^l}=\mathcal{H}_L^{l, m}(\frac{l}{L}(m-\varepsilon k)).
\end{multline*}

При это мы получили ограничение на $s$, которое является следствием того, что переобученность $\leq \varepsilon$. Наша оценка $-$ левый хвост гипергеометрического распределения.
$\blacksquare$

Посмотрим как это выглядит на картинке. На оси $x$ отложено $m$ $-$ общее число ошибок на полной выборке, по оси $y$ откладывается число ошибок на обучающей выборке. На графике \ref{fig:pic3} видна узкая полоска $-$ \textit{явление концентрации вероятностной меры}. Это очень важное явление и в теории вероятности, и в машинном обучении, и в Computational learning theory. Это основной теоретический момент, из которого могут быть получены различные оценки (красная полоска). При том чем больше будет длина выборки, тем уже будет относительная ширина этой полоски.

Предсказание числа $m=n(a, X^L)$ по числу $s=n(a, X^l)$ возможно благодаря узости гипергеометрического пика, причем при $l,k \rightarrow \infty$ он сужается, и $\nu(a, X^l) \rightarrow \nu(a, X^k)$ (явление концентрации вероятности, закон больших чисел).

Гипергеометрическое распределение нам говорит, что если мы знаем $m$ (общее число ошибок на полной выборке), то мы можем предсказать диапазон изменений для $s$, т. е. сколько у нас ошибок попадет в обучение. Значит будем знать $m-s$, сколько ошибок попадет в контроль. Но в реальной ситуации нам приходиться обращать это гипергеометрическое распределение, т. к. мы знаем сколько ошибок у нас попало в обучение. Мы знаем что у нас по $y$ и можем провести горизонтальную линию и сказать, в каком у нас диапазоне могло бы быть $m$, т. е. в каком диапазоне могло бы лежать общее число ошибок на объединенной выборке. А $m-s$ это число ошибок на контроле.

\begin{figure}[hbt!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.8]
            \begin{axis}[
                grid=both,
                xlabel={$h(s|m)$},
                ylabel={$s$},
                ymin=-5, ymax=105,
                xmin=-0.01, xmax=0.13,
                tick align=outside
            ]
                \addplot[red, thick, domain=0:50, samples=100] (0.12*exp(-(x-25)*(x-25)),x);
                \addplot[color=black, thick, dashed] coordinates {(0, 0) (0.12, 0)};
                \addplot[color=black, thick, dashed] coordinates {(0, 20) (0.12, 20)};
                \addplot[color=black, thick, dashed] coordinates {(0, 30) (0.12, 30)};
                \addplot[color=black, thick, dashed] coordinates {(0, 50) (0.12, 50)};
            \end{axis}
        \end{tikzpicture}
        \caption{$h(s|m)$ при $m=50$}
        \label{fig:pic3}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale=0.8]
            \begin{axis}[
                grid=both,
                xlabel={$m$},
                ylabel={$s$},
                xmin=-5, xmax=205,
                ymin=-5, ymax=105,
            ]
                % Main diagonal
                \addplot[red, domain=0:200, samples=100, dashdotted] {x/2};
                % Shaded region
                \addplot[name path=A, domain=10:200, samples=100, thick, dashed] {x/2 - 5};
                \addplot[name path=B, domain=0:190, samples=100, thick, dashed] {x/2 + 5};
    
                \addplot[name path=seg1, color=black, thick] coordinates {(0, 0) (100, 100)};
                \addplot[name path=seg2, color=black, thick] coordinates {(100, 100) (200, 100)};
                \addplot[name path=seg3, color=black, thick] coordinates {(200, 100) (100, 0)};
                \addplot[name path=seg4, color=black, thick] coordinates {(100, 0) (0, 0)};
                \addplot[red, opacity=0.3] fill between[of=seg1 and seg4];
                \addplot[red, opacity=0.3] fill between[of=seg2 and seg3];
    
                \addplot[red, opacity=0.3] fill between[of=A and B];
                \addplot[color=black, thick, dashed] coordinates {(0, 50) (50, 50)};
                \addplot[color=black, thick, dashed] coordinates {(0, 30) (50, 30)};
                \addplot[color=black, thick, dashed] coordinates {(0, 20) (50, 20)};
                \addplot[color=black, thick, dashed] coordinates {(0, 0) (50, 0)};
                \addplot[color=black, <->] coordinates {(50, 0) (50, 50)};
            \end{axis}
        \end{tikzpicture}
        \caption{$h(s|m)$ при $L=200, k=100$}
        \label{fig:pic4}
    \end{subfigure}
    \caption{Гипергеометрическое распределение $h(s|m)$}
\end{figure}

\textbf{Задача 1.} Сколько линейных классификаторов с двумя ошибками из примера 1?

\textbf{Решение.}

Для решения задачи необходимо посмотреть сколько существует различных способов разделить объекты на рисунке \ref{fig:pic1}, чтобы объектов одного класса было на 2 больше, чем другого. Приведем ответ в виде таблицы:

\begin{table}[hbt!]
    \begin{tabular}{c|cccccccc}
		$x_1$ & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 \\
    $x_2$ & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
		$x_3$ & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 \\
    $x_4$ & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
    $x_5$ & 0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 \\
    $x_6$ & 0 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
    $x_7$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    $x_8$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    $x_9$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
 $x_{10}$ & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \end{tabular}
    \caption{все возможные разбиения с 2 ошибками}
\end{table}

\textbf{Задача 2.} В урне $L$ шаров, $m$ из них черные, остальные белые; извлекаем $l$ шаров наугад. Какова вероятность, что ровно $s$ из них черные?

\textbf{Решение.}

Обозначим:
$N = L$ $-$ общее количество шаров в урне,
$m$ $-$ количество черных шаров,
$N - m$ $-$ количество белых шаров,
$l$ $-$ общее количество извлеченных шаров,
$s$ $-$ количество черных шаров среди извлеченных.

Чтобы найти вероятность, нам нужно рассмотреть, сколько способов существует для выбора $s$ черных шаров и $l - s$ белых шаров из общего количества.

Выбрать $s$ черных шаров из $m$ черных можно $C_m^s$ способами.

А выбрать $l - s$ белых шаров из $N - m$ белых $-$ $ C_{N - m}^{l - s}$ способами.

Общее количество способов выбрать $l$ шаров из $N$ есть $C_N^l$.

Таким образом, вероятность того, что из $l$ извлеченных шаров ровно $s$ будут черными, будет равна отношению числа благоприятных исходов к общему числу исходов:

$$
P(X = s) = \frac{C_{m}^{s} \cdot C_{N - m}^{l - s}}{C_{N}^{l}}
$$

\textbf{Задача 3.} Как посчитать количество рыб в пруду?

\textbf{Решение.} Выловим некоторое случайное подмножество рыб, пометим их, а потом выпустим обратно в пруд. Через некоторое время рыбы в пруду перемешаются (важно, чтобы они успели перемешаться), опять вылавливаем некоторое количество рыб и смотрим, какая доля среди них $-$ меченная. По этим данным, очевидно, можно найти общее количество рыб в пруду.


\section{Статистические критерии в машинном обучении}
\subsection{Теория}

Статистические инструменты используются для отбора, извлечения и преобразования наиболее релевантных признаков. Например, коэффициент корреляции Пирсона, ранговый коэффициент Спирмена, коэффициент корреляции ANOVA, ранговый коэффициент Кендалла и критерий  Хи-квадрат \\

В данном обзоре рассмотрим приложения математической статистики в машинном обучении – точнее, в отборе признаков для обучения модели.  \\

Мотивация: Преимущества хорошо подобранных признаков в датасете очевидны: это улучшает точность в обучении с учителем и без, уменьшает время и память, необходимые для корректной работы, помогает ослабить проклятие размерности (экспоненциальный рост необходимых данных). \\

Одним из основных методов, используемых для отбора признаков, является анализ корреляции. Корреляция позволяет определить, насколько сильно связаны между собой различные признаки и целевая переменная. Признаки с высокой корреляцией с целевой переменной могут быть отобраны для дальнейшего анализа, в то время как признаки, которые не имеют значительной связи, могут быть исключены. Это помогает избежать проблем многоколлинеарности, когда несколько признаков предоставляют одинаковую информацию.\\

Другим важным инструментом является тестирование гипотез. С помощью статистических тестов, таких как t-тест или ANOVA, можно оценить значимость отдельных признаков в контексте целевой переменной. Например, если мы имеем дело с задачей классификации, мы можем использовать тесты для определения того, какие признаки значительно различаются между классами. Это позволяет сосредоточиться на наиболее информативных признаках и исключить те, которые не вносят существенного вклада в модель.\\

Методы селекции на основе значимости также широко применяются в практике. Алгоритмы, такие как LASSO (Least Absolute Shrinkage and Selection Operator), используют регуляризацию для уменьшения коэффициентов менее значимых признаков до нуля, что автоматически исключает их из модели. Это не только упрощает модель, но и помогает избежать переобучения — проблемы, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать на новых данных.\\

Методы оценки производительности модели также зависят от правильного отбора признаков. Кросс-валидация позволяет оценить, как изменения в наборе признаков влияют на общую производительность модели. Сравнение различных моделей с разными наборами признаков помогает выбрать оптимальный вариант, который обеспечивает наилучшие результаты.\\

Кроме того, современные подходы к машинному обучению, такие как ансамблевые методы (например, Random Forest), также используют статистические методы для оценки важности признаков. В таких методах важность каждого признака может быть оценена по тому, как сильно он влияет на уменьшение ошибки предсказания модели. \\

\subsection{Задачи}

1. Анализ корреляции\\
У вас есть набор данных с 5 признаками (X1, X2, X3, X4, X5) и целевой переменной Y. Вы хотите выяснить, какие признаки имеют наибольшую корреляцию с Y.

\textit{Решение:\\
1. Рассчитайте коэффициенты корреляции Пирсона для каждого признака относительно Y.\\
2. Сравните полученные значения и выберите признаки с наибольшими абсолютными значениями коэффициента корреляции.}
   
2. Тестирование гипотез\\
Вы хотите проверить, есть ли статистически значимая разница между двумя группами данных (группа A и группа B) по признаку X. У вас есть данные о значениях X для обеих групп.

\textit{Решение:\\
1. Проведите t-тест для независимых выборок.\\
2. Оцените p-значение для определения значимости.}

3. Регуляризация LASSO \\
У вас есть набор данных с несколькими признаками и целевой переменной. Вы хотите использовать метод LASSO для отбора наиболее значимых признаков.

\textit{Решение:\\
1. Импортируйте библиотеку Lasso из sklearn.\\
2. Подготовьте данные и обучите модель LASSO.\\
3. Оцените важность признаков на основе полученных коэффициентов.\\}

